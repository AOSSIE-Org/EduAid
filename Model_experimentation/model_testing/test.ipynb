{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KeyPhrase Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keyphrase-vectorizers\n",
      "  Downloading keyphrase_vectorizers-0.0.13-py3-none-any.whl.metadata (47 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in e:\\eduaid\\venv\\lib\\site-packages (from keyphrase-vectorizers) (1.26.4)\n",
      "Requirement already satisfied: spacy>=3.0.1 in e:\\eduaid\\venv\\lib\\site-packages (from keyphrase-vectorizers) (3.7.5)\n",
      "Collecting spacy-transformers>=1.1.6 (from keyphrase-vectorizers)\n",
      "  Downloading spacy_transformers-1.3.8-cp312-cp312-win_amd64.whl.metadata (7.2 kB)\n",
      "Collecting spacy-curated-transformers>=0.2.2 (from keyphrase-vectorizers)\n",
      "  Downloading spacy_curated_transformers-2.1.2-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: nltk>=3.6.1 in e:\\eduaid\\venv\\lib\\site-packages (from keyphrase-vectorizers) (3.9.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0 in e:\\eduaid\\venv\\lib\\site-packages (from keyphrase-vectorizers) (1.5.2)\n",
      "Requirement already satisfied: scipy>=1.7.3 in e:\\eduaid\\venv\\lib\\site-packages (from keyphrase-vectorizers) (1.14.1)\n",
      "Requirement already satisfied: psutil>=5.8.0 in e:\\eduaid\\venv\\lib\\site-packages (from keyphrase-vectorizers) (7.0.0)\n",
      "Requirement already satisfied: click in e:\\eduaid\\venv\\lib\\site-packages (from nltk>=3.6.1->keyphrase-vectorizers) (8.1.8)\n",
      "Requirement already satisfied: joblib in e:\\eduaid\\venv\\lib\\site-packages (from nltk>=3.6.1->keyphrase-vectorizers) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\eduaid\\venv\\lib\\site-packages (from nltk>=3.6.1->keyphrase-vectorizers) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in e:\\eduaid\\venv\\lib\\site-packages (from nltk>=3.6.1->keyphrase-vectorizers) (4.67.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\eduaid\\venv\\lib\\site-packages (from scikit-learn>=1.0->keyphrase-vectorizers) (3.5.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in e:\\eduaid\\venv\\lib\\site-packages (from spacy>=3.0.1->keyphrase-vectorizers) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in e:\\eduaid\\venv\\lib\\site-packages (from spacy>=3.0.1->keyphrase-vectorizers) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in e:\\eduaid\\venv\\lib\\site-packages (from spacy>=3.0.1->keyphrase-vectorizers) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in e:\\eduaid\\venv\\lib\\site-packages (from spacy>=3.0.1->keyphrase-vectorizers) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in e:\\eduaid\\venv\\lib\\site-packages (from spacy>=3.0.1->keyphrase-vectorizers) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in e:\\eduaid\\venv\\lib\\site-packages (from spacy>=3.0.1->keyphrase-vectorizers) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in e:\\eduaid\\venv\\lib\\site-packages (from spacy>=3.0.1->keyphrase-vectorizers) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in e:\\eduaid\\venv\\lib\\site-packages (from spacy>=3.0.1->keyphrase-vectorizers) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in e:\\eduaid\\venv\\lib\\site-packages (from spacy>=3.0.1->keyphrase-vectorizers) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in e:\\eduaid\\venv\\lib\\site-packages (from spacy>=3.0.1->keyphrase-vectorizers) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in e:\\eduaid\\venv\\lib\\site-packages (from spacy>=3.0.1->keyphrase-vectorizers) (0.15.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in e:\\eduaid\\venv\\lib\\site-packages (from spacy>=3.0.1->keyphrase-vectorizers) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in e:\\eduaid\\venv\\lib\\site-packages (from spacy>=3.0.1->keyphrase-vectorizers) (2.10.6)\n",
      "Requirement already satisfied: jinja2 in e:\\eduaid\\venv\\lib\\site-packages (from spacy>=3.0.1->keyphrase-vectorizers) (3.1.5)\n",
      "Requirement already satisfied: setuptools in e:\\eduaid\\venv\\lib\\site-packages (from spacy>=3.0.1->keyphrase-vectorizers) (75.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\eduaid\\venv\\lib\\site-packages (from spacy>=3.0.1->keyphrase-vectorizers) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in e:\\eduaid\\venv\\lib\\site-packages (from spacy>=3.0.1->keyphrase-vectorizers) (3.5.0)\n",
      "Collecting curated-transformers<3.0.0,>=2.0.0 (from spacy-curated-transformers>=0.2.2->keyphrase-vectorizers)\n",
      "  Downloading curated_transformers-2.0.1-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting curated-tokenizers<3.0.0,>=2.0.0 (from spacy-curated-transformers>=0.2.2->keyphrase-vectorizers)\n",
      "  Downloading curated_tokenizers-2.0.0-cp312-cp312-win_amd64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in e:\\eduaid\\venv\\lib\\site-packages (from spacy-curated-transformers>=0.2.2->keyphrase-vectorizers) (2024.9.0)\n",
      "INFO: pip is looking at multiple versions of spacy-curated-transformers to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting spacy-curated-transformers>=0.2.2 (from keyphrase-vectorizers)\n",
      "  Downloading spacy_curated_transformers-2.1.1-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy>=3.0.1 (from keyphrase-vectorizers)\n",
      "  Downloading spacy-4.0.0.dev3-cp312-cp312-win_amd64.whl.metadata (26 kB)\n",
      "Collecting spacy-curated-transformers>=0.2.2 (from keyphrase-vectorizers)\n",
      "  Downloading spacy_curated_transformers-2.0.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "  Downloading spacy_curated_transformers-0.3.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting curated-transformers<0.2.0,>=0.1.0 (from spacy-curated-transformers>=0.2.2->keyphrase-vectorizers)\n",
      "  Downloading curated_transformers-0.1.1-py2.py3-none-any.whl.metadata (965 bytes)\n",
      "Collecting curated-tokenizers<0.1.0,>=0.0.9 (from spacy-curated-transformers>=0.2.2->keyphrase-vectorizers)\n",
      "  Downloading curated_tokenizers-0.0.9-cp312-cp312-win_amd64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: torch>=1.12.0 in e:\\eduaid\\venv\\lib\\site-packages (from spacy-curated-transformers>=0.2.2->keyphrase-vectorizers) (2.5.1)\n",
      "Requirement already satisfied: transformers<4.50.0,>=3.4.0 in e:\\eduaid\\venv\\lib\\site-packages (from spacy-transformers>=1.1.6->keyphrase-vectorizers) (4.46.1)\n",
      "Collecting spacy-alignments<1.0.0,>=0.7.2 (from spacy-transformers>=1.1.6->keyphrase-vectorizers)\n",
      "  Downloading spacy_alignments-0.9.1-cp312-cp312-win_amd64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: language-data>=1.2 in e:\\eduaid\\venv\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3.0.1->keyphrase-vectorizers) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\eduaid\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.1->keyphrase-vectorizers) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in e:\\eduaid\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.1->keyphrase-vectorizers) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in e:\\eduaid\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.1->keyphrase-vectorizers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\eduaid\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->keyphrase-vectorizers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\eduaid\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->keyphrase-vectorizers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\eduaid\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->keyphrase-vectorizers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\eduaid\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->keyphrase-vectorizers) (2025.1.31)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in e:\\eduaid\\venv\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy>=3.0.1->keyphrase-vectorizers) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in e:\\eduaid\\venv\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy>=3.0.1->keyphrase-vectorizers) (0.1.5)\n",
      "Requirement already satisfied: filelock in e:\\eduaid\\venv\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers>=0.2.2->keyphrase-vectorizers) (3.17.0)\n",
      "Requirement already satisfied: networkx in e:\\eduaid\\venv\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers>=0.2.2->keyphrase-vectorizers) (3.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in e:\\eduaid\\venv\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers>=0.2.2->keyphrase-vectorizers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\eduaid\\venv\\lib\\site-packages (from sympy==1.13.1->torch>=1.12.0->spacy-curated-transformers>=0.2.2->keyphrase-vectorizers) (1.3.0)\n",
      "Requirement already satisfied: colorama in e:\\eduaid\\venv\\lib\\site-packages (from tqdm->nltk>=3.6.1->keyphrase-vectorizers) (0.4.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in e:\\eduaid\\venv\\lib\\site-packages (from transformers<4.50.0,>=3.4.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (0.29.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\eduaid\\venv\\lib\\site-packages (from transformers<4.50.0,>=3.4.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (6.0.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in e:\\eduaid\\venv\\lib\\site-packages (from transformers<4.50.0,>=3.4.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (0.5.2)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in e:\\eduaid\\venv\\lib\\site-packages (from transformers<4.50.0,>=3.4.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (0.20.3)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in e:\\eduaid\\venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy>=3.0.1->keyphrase-vectorizers) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in e:\\eduaid\\venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy>=3.0.1->keyphrase-vectorizers) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in e:\\eduaid\\venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.0.1->keyphrase-vectorizers) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in e:\\eduaid\\venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.0.1->keyphrase-vectorizers) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\eduaid\\venv\\lib\\site-packages (from jinja2->spacy>=3.0.1->keyphrase-vectorizers) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in e:\\eduaid\\venv\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3.0.1->keyphrase-vectorizers) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in e:\\eduaid\\venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.0.1->keyphrase-vectorizers) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in e:\\eduaid\\venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.0.1->keyphrase-vectorizers) (2.19.1)\n",
      "Requirement already satisfied: wrapt in e:\\eduaid\\venv\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=3.0.1->keyphrase-vectorizers) (1.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in e:\\eduaid\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.0.1->keyphrase-vectorizers) (0.1.2)\n",
      "Downloading keyphrase_vectorizers-0.0.13-py3-none-any.whl (34 kB)\n",
      "Downloading spacy_curated_transformers-0.3.0-py2.py3-none-any.whl (236 kB)\n",
      "Downloading spacy_transformers-1.3.8-cp312-cp312-win_amd64.whl (343 kB)\n",
      "Downloading curated_tokenizers-0.0.9-cp312-cp312-win_amd64.whl (731 kB)\n",
      "   ---------------------------------------- 0.0/731.5 kB ? eta -:--:--\n",
      "   ---------------------------- ----------- 524.3/731.5 kB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 731.5/731.5 kB 1.7 MB/s eta 0:00:00\n",
      "Downloading curated_transformers-0.1.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading spacy_alignments-0.9.1-cp312-cp312-win_amd64.whl (187 kB)\n",
      "Installing collected packages: spacy-alignments, curated-tokenizers, curated-transformers, spacy-curated-transformers, spacy-transformers, keyphrase-vectorizers\n",
      "Successfully installed curated-tokenizers-0.0.9 curated-transformers-0.1.1 keyphrase-vectorizers-0.0.13 spacy-alignments-0.9.1 spacy-curated-transformers-0.3.0 spacy-transformers-1.3.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install keyphrase-vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keybert\n",
      "  Downloading keybert-0.9.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in e:\\eduaid\\venv\\lib\\site-packages (from keybert) (1.26.4)\n",
      "Requirement already satisfied: rich>=10.4.0 in e:\\eduaid\\venv\\lib\\site-packages (from keybert) (13.9.4)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in e:\\eduaid\\venv\\lib\\site-packages (from keybert) (1.5.2)\n",
      "Collecting sentence-transformers>=0.3.8 (from keybert)\n",
      "  Downloading sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in e:\\eduaid\\venv\\lib\\site-packages (from rich>=10.4.0->keybert) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in e:\\eduaid\\venv\\lib\\site-packages (from rich>=10.4.0->keybert) (2.19.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in e:\\eduaid\\venv\\lib\\site-packages (from scikit-learn>=0.22.2->keybert) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in e:\\eduaid\\venv\\lib\\site-packages (from scikit-learn>=0.22.2->keybert) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\eduaid\\venv\\lib\\site-packages (from scikit-learn>=0.22.2->keybert) (3.5.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in e:\\eduaid\\venv\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (4.46.1)\n",
      "Requirement already satisfied: tqdm in e:\\eduaid\\venv\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in e:\\eduaid\\venv\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (2.5.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in e:\\eduaid\\venv\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (0.29.1)\n",
      "Collecting Pillow (from sentence-transformers>=0.3.8->keybert)\n",
      "  Using cached pillow-11.1.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: filelock in e:\\eduaid\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in e:\\eduaid\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in e:\\eduaid\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\eduaid\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (6.0.2)\n",
      "Requirement already satisfied: requests in e:\\eduaid\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in e:\\eduaid\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (4.12.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in e:\\eduaid\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.2)\n",
      "Requirement already satisfied: networkx in e:\\eduaid\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.1)\n",
      "Requirement already satisfied: jinja2 in e:\\eduaid\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.1.5)\n",
      "Requirement already satisfied: setuptools in e:\\eduaid\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in e:\\eduaid\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\eduaid\\venv\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.3.0)\n",
      "Requirement already satisfied: colorama in e:\\eduaid\\venv\\lib\\site-packages (from tqdm->sentence-transformers>=0.3.8->keybert) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in e:\\eduaid\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in e:\\eduaid\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (0.5.2)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in e:\\eduaid\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (0.20.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\eduaid\\venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\eduaid\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\eduaid\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\eduaid\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\eduaid\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2025.1.31)\n",
      "Downloading keybert-0.9.0-py3-none-any.whl (41 kB)\n",
      "Downloading sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\n",
      "Using cached pillow-11.1.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "Installing collected packages: Pillow, sentence-transformers, keybert\n",
      "Successfully installed Pillow-11.1.0 keybert-0.9.0 sentence-transformers-3.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install keybert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=[\n",
    "    \"\"\"\n",
    "Mitochondria are double-membraned organelles found in most eukaryotic cells. They are often referred to as the \"powerhouses\" of the cell because they generate most of the cell's energy in the form of adenosine triphosphate (ATP). Mitochondria play a crucial role in cellular respiration, which is the process by which cells convert nutrients into usable energy.\n",
    "The structure of mitochondria consists of an outer membrane, which surrounds the entire organelle, and an inner membrane that is highly folded to form structures called cristae. The inner membrane encloses the mitochondrial matrix, which contains enzymes and DNA molecules necessary for various metabolic reactions.\n",
    "One of the primary functions of mitochondria is to carry out aerobic respiration, a process that uses oxygen to break down glucose and other organic molecules, releasing energy in the form of ATP. This process occurs in the inner membrane of the mitochondria, specifically in the electron transport chain and the citric acid cycle.\n",
    "Apart from energy production, mitochondria have other important roles in the cell. They are involved in the regulation of cellular metabolism, calcium signaling, and apoptosis (programmed cell death). Mitochondria also contain their own DNA, known as mitochondrial DNA (mtDNA), which is separate from the nuclear DNA found in the cell's nucleus.\n",
    "\n",
    "It's worth noting that while mitochondria are present in most eukaryotic cells, certain cell types may have varying numbers of mitochondria depending on their energy requirements. For example, muscle cells and liver cells often contain a higher number of mitochondria due to their high energy demands.\n",
    "\n",
    "\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keyphrase_vectorizers import KeyphraseCountVectorizer\n",
    "vectorizer=KeyphraseCountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 51)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_keyphrase_matrix=vectorizer.fit_transform(docs).toarray()\n",
    "document_keyphrase_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kB=KeyBERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mitochondria', 0.6586),\n",
       " ('cellular metabolism', 0.541),\n",
       " ('cellular respiration', 0.5234),\n",
       " ('organelles', 0.5204),\n",
       " ('mitochondrial matrix', 0.5142)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kB.extract_keywords(docs=docs,vectorizer=vectorizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer Aware Question Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../SQuAD/train-v2.0.json','r') as f:\n",
    "    data=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts=[]\n",
    "answers=[]\n",
    "questions=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for article in data['data']:\n",
    "    for paragraph in article['paragraphs']:\n",
    "        context=paragraph['context']\n",
    "        for qa in paragraph['qas']:\n",
    "            question=qa['question']\n",
    "            for answer in qa['answers']:\n",
    "                answer_text=answer['text']\n",
    "                contexts.append(context)\n",
    "                answers.append(answer_text)\n",
    "                questions.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQuAD_data={\n",
    "    'Question': questions,\n",
    "    'Answer': answers,\n",
    "    'Context': contexts\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame(SQuAD_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>singing and dancing</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question               Answer  \\\n",
       "0           When did Beyonce start becoming popular?    in the late 1990s   \n",
       "1  What areas did Beyonce compete in when she was...  singing and dancing   \n",
       "\n",
       "                                             Context  \n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...  \n",
       "1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86821"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample=data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionGenerationDataset(Dataset):\n",
    "    def __init__(self, context_list, answer_list, question_list, tokenizer):\n",
    "        self.context_list = context_list\n",
    "        self.answer_list = answer_list\n",
    "        self.question_list = question_list\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.context_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        context = self.context_list[idx]\n",
    "        answer = self.answer_list[idx]\n",
    "        question = self.question_list[idx]\n",
    "\n",
    "        input_text = f\"generate question: {context} Answer: {answer}\"\n",
    "        target_text = question\n",
    "\n",
    "        input_ids = self.tokenizer.encode(input_text, truncation=True, padding='max_length', max_length=512, return_tensors='pt')[0]\n",
    "        target_ids = self.tokenizer.encode(target_text, truncation=True, padding='max_length', max_length=32, return_tensors='pt')[0]\n",
    "\n",
    "        return {\"input_ids\": input_ids, \"attention_mask\": input_ids.ne(0), \"target_ids\": target_ids, \"target_attention_mask\": target_ids.ne(0)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_list=data_sample['Context'].tolist()\n",
    "answer_list=data_sample['Answer'].tolist()\n",
    "question_list=data_sample['Question'].tolist()\n",
    "\n",
    "tokenizer=T5Tokenizer.from_pretrained('t5-base')\n",
    "dataset=QuestionGenerationDataset(context_list,answer_list,question_list,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=T5ForConditionalGeneration.from_pretrained('t5-base')\n",
    "epochs=3\n",
    "batch_size=2\n",
    "learning_rate=0.0001\n",
    "dataloader=DataLoader(dataset,batch_size=batch_size, shuffle=True)\n",
    "device =torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model.to(device)\n",
    "optimizer=AdamW(model.parameters(),lr=learning_rate)\n",
    "scheduler=torch.optim.lr_scheduler.StepLR(optimizer,step_size=1,gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 50/50 [18:05<00:00, 21.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Loss: 2.189678477048874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 50/50 [19:25<00:00, 23.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 - Loss: 0.9359392833709717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 50/50 [18:46<00:00, 22.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 - Loss: 0.9229644989967346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_t5_tokenizer\\\\tokenizer_config.json',\n",
       " './fine_tuned_t5_tokenizer\\\\special_tokens_map.json',\n",
       " './fine_tuned_t5_tokenizer\\\\spiece.model',\n",
       " './fine_tuned_t5_tokenizer\\\\added_tokens.json')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(dataloader,desc=f'Epoch {epoch}'):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        target_ids = batch['target_ids'].to(device)\n",
    "        target_attention_mask = batch['target_attention_mask'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=target_ids, decoder_attention_mask=target_attention_mask)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss}\")\n",
    "\n",
    "model.save_pretrained(\"./fine_tuned_t5_model\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_t5_tokenizer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_question(answer,context,model,tokenizer):\n",
    "    input_text=f'generate question: {context} Answer: {answer}'\n",
    "    input_ids=tokenizer.encode(input_text, truncation=True, padding='max_length', max_length=512, return_tensors='pt').to(device)\n",
    "    output=model.generate(input_ids)\n",
    "    generated_question=tokenizer.decode(output[0],skip_special_tokens=True)\n",
    "    return generated_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Prarabdh Shukla\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\utils.py:1346: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mitochondria are often referred to as the \"powerhouses\"\n"
     ]
    }
   ],
   "source": [
    "extracted_keyword='mitochondria'\n",
    "print(generate_question(extracted_keyword,docs[0], model,tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Prarabdh Shukla\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\utils.py:1346: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entailment of this article.\n"
     ]
    }
   ],
   "source": [
    "print(generate_question('cellular metabolism',docs[0],model,tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Prarabdh Shukla\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\utils.py:1346: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adenosine triphosphate (ATP) is the most common ATP\n"
     ]
    }
   ],
   "source": [
    "print(generate_question('adenosine triphosphate', docs[0],model, tokenizer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
